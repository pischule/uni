\chapter*{СПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ}
\addcontentsline{toc}{chapter}{CПИСОК ИСПОЛЬЗОВАННЫХ ИСТОЧНИКОВ}

\begin{enumerate}


    % \item \label{itm:sutton} Richard S. Sutton, Andrew G. Barto, Reinforcement Learning: An Introduction, MIT Press, Cambridge, MA, 1998
    % \item \label{itm:q-learning} Q-обучение // Википедия. [2019]. Дата обновления: 02.08.2019. URL: \url{https://ru.wikipedia.org/?curid=2191534&oldid=101393871} (дата обращения: 02.08.2019).
    % \item \label{itm:last} Крестики-нолики // Википедия. [2020]. Дата обновления: 14.11.2020. URL: \url{https://ru.wikipedia.org/?curid=199848&oldid=110488410} (дата обращения: 14.11.2020).

    % Закон сохранения импульса [Электронный ресурс] / Wikipedia Project – Дата доступа: 10.12.2015. – Режим доступа: https://ru.wikipedia.org/wiki/Закон_сохранения_импульса.
    
    % Рихтер, Джеффри. CLR via C#. Программирование на платформе Microsoft .NET Framework 4.0 на языке C#, 3-е издание / Джеффри Рихтер. – в переводе на русский язык, Санкт-Петербург: «Питер», 2012. – 320 с.
    
    % \item \label{itm:sutton} Richard S. Sutton. Reinforcement Learning: An Introduction / Richard S. Sutton, Andrew G. Barto – 2nd ed. – MIT Press, Cambridge, MA, 1998. – 352 p.
    
            
    % \item \label{itm:russell} Stuart J. Russell. Artificial Intelligence: A Modern Approach / Stuart J. Russell, Peter Norvig - 3rd ed. - Prentice Hall, Upper Saddle River, NJ, 2010. - 659 p.
    
    % \item \label{itm:wiering} Marco Wiering, Reinforcement Learning: State-of-the-art. / Marco Wiering, Martijn van Otterlo - Springer-Verlag, Berlin, 2012. - 638 p.
    
    % \item \label{itm:last} Гарднер М. Крестики-нолики. / Гарднер М. // — Крестики-нолики или тик-так-тоу / Гарднер М. - Гл. 9. - Москва: Мир, 1988. - С. 135 - 151.
    
    \item Andreopoulos, A., and Tsotsos, J. K. (2013). 50 years of object recognition: directions forward. Comput. Vis. Image Underst. 117, 827–891
    
    \item A. Khan, A. Sohail, U. Zahoora, and A. S. Qureshi, “A survey of the recent architectures of deep convolutional neural networks,”
    
    \item O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei, “Imagenet large scale visual recognition challenge,” International Journal of Computer Vision, vol. 115, pp. 211–252
    
    \item K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image recognition,” in 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770–778
    
    % \item \label{itm:yizheng} Yizheng Liao, Kun Yi, Zhe Yang: Reinforcement Learning to Play Mario, CS229. 
    % \item \label{itm:bing} Bing-Qiang Huang, Gung-Yi Cao, Min Guo: Reinforcement Learning Neural Network to the problem of autonomous mobile robot obstacle avoidance, 18-21, (2005). 
    % \item \label{itm:michael} Michiel R., Marco W.: Reinforcement Learning in the Game of Othello: Learning Against a Fixed Opponent and Learning from Self-Play 

    % \item \label{itm:imran} Imran Ghory: Reinforcement learning in board games. 

    % \item \label{itm:last} Гарднер М. Крестики-нолики. / Гарднер М. // — YOLOv3: An Incremental Improvement / Гарднер М. - Гл. 9. - Москва: Мир, 1988. - С. 135 - 151.

    % \item \label{itm:sutton} Richard S. Sutton, Andrew G. Barto, Reinforcement Learning: An Introduction, MIT Press, Cambridge, MA, 1998
    
\end{enumerate}

\newpage